


We wish to incorporate meta-data filters:

So, here are some meta-data filters:

domain
field
contains_authors
contains_title
type: (journal-article, book, book-chapter, pre-print,...)

we can use binary embeddings (list of integers) as filters for meta-data.

Read the quadrant article.





m:14612host:53387verified10 GB627.9 GB/s
H12SSL
10x RTX 3080
Motherboard: H12SSLPCIE 4.0,8x12.8 GB/s
AMD EPYC 7B13 64-Core Processor
128.0/128 cpu225/225 GB
Storage
4578 MB/s1364.0 GB68 Mbps69 Mbps998 ports169.6 DLPerfMax CUDA: 12.4Max Duration
1 mon, 13d
Reliability95.1%159.3 DLP/$/hr
$1.064/hr


m:7618datacenter:11885verified24 GB627.4 GB/s
S7109GM2NR
PCIE 3.0,16xNumber of PCIE lanes Per GPU11.7 GB/s
Xeon® Silver 4110
32.0/32 cpu129/129 GB
Samsung SSD 860
495 MB/s278.8 GB359 Mbps437 Mbps98 ports143.0 DLPerfMax CUDA: 12.0Max Duration
12 days
Reliability99.55%875.3 DLP/$/hr
$0.187/hr






3828host:4535verified12 GB467.1 GB/s
158B
PCIE 3.0,16x11.3 GB/s
Xeon® E5-2630 v2
24.0/24 cpu32/32 GB
INTEL SSDPEDMX020T4
2262 MB/s1350.0 GB775 Mbps881 Mbps48 ports34.5 DLPerfMax CUDA: 12.5Max Duration
1 mon, 14d
Reliability99.89%650.4 DLP/$/hr
$0.060/hr




Here is how we could use meta-data filtering:

We wish to create a filter that is a vector with integer encodings for the following

"contains_title"
"contains_topic"
"contains_authors"
"char_len_above_20"
"char_len_above_50"
"field_type" (0 to 25)
"subfield_type" (0 to ?)
"topic_type" (0 to ?)

So, around 8 dimensional vector should do it for us.
We wanna create a method that generates this parquet file.


Total 5000000
Processing works: 5131578it [43:40, 1634.70it/s]Saved batch 49 to E:\HugeDatasetBackup\cloud_datasets\works_batch_49.parquet
Memory usage at for 5000000: 4858.56 MB
Processed 5000000 works
Total 5000000
Memory usage at before concatenation: 4858.57 MB
Processing works: 5132420it [43:54, 1948.06it/s]
sys:1: CategoricalRemappingWarning: Local categorical have different encodings, expensive re-encoding is done to perform this merge operation. Consider using a StringCache or an Enum type if the categories are known in advance
Memory usage at After concatenation: 10037.75 MB


I wish to make a trimmed version of Works collection. TRIMMED, with meta-data filter vectors.

500GB of ram for polars load, maybe need 1.5TB to save the polars dataframe.

We need to come up with a big solution for common authors file,

making it without having ram considerations will be a big problem.

==================================================================================================================




==================================================================================================================

One: We will make a classifier that decides which search engine, and which filters to use:

We do knn search over various vectordb, then join the results, then










