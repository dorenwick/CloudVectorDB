Here is how we are going to build a huge dataset of triplets, then train an amazing encoder on it.

We have 2TB of ram, and 2TB of sdd space.

1 We will start by importing in the mongodb, which has works collection, and the authors' collection.


2 Second, we will build unigram parquet files and bigram parquet files, scoring every unigram/bigram in title+authors,
as well as in the abstracts. So we make a unigram/bigram for abstracts, and unigram/bigram for titles+authors.


3 Third of all, we will build a parquet file that contains every work pair with an author in common.
This will go through the mongodb collection.

As we do this, we will add to dataframes a bunch of data that includes work_id, strings, unigrams, bigrams,

-- We are essentially going to copy our old script, but adjust it so that it doesn't create big chunks of data.
We will also have to do big directory changes as well.
-- Also, we will have to fix it up so that it so there is persistent garbage collection, as well as
using gpu parallelism, and also we will train a larger model and a smaller model, and probably we will fix them both up
to be fine-tuned for authors, and for titles.
-- Then, once its all done, we will create a big vector db with them.

----------------------------------------------------------------




:26619host:148507verified80 GB1433.6 GB/s300.0 GB/s
Asm
PCIE 4.0,16x24.8 GB/s
AMD EPYC 7J13 64-Core Processor
CPU: AMD EPYC 7J13 64-Core Processor32.0/256 cpu258/2064 GB
SAMSUNG MZWLJ7T6HALA-00AU3
5133 MB/s592.8 GB6891 Mbps9489 Mbps124 ports136.7 DLPerfMax CUDA: 12.2Max Duration
9 days
Reliability99.46%185.7 DLP/$/hr
$0.736/hr















































Once that is done, we will get to work on the other vectordb that we have in mind.

Type #11905732
Arizona, US8x A100 SXM4124.7  TFLOPSm:26537host:148507verified80 GB1431.3 GB/s
Asm
PCIE 4.0,16x23.2 GB/s
AMD EPYC 7J13 64-Core Processor
256.0/256 cpu2064/2064 GB
SAMSUNG MZWLJ7T6HALA-00AU3
5545 MB/s5154.8 GB5776 Mbps12112 Mbps998 ports581.5 DLPerfMax CUDA: 12.2Max Duration
10 days
Reliability99.47%91.9 DLP/$/hr
Price Breakdown
GPU On-Demand:
5.867 $/hr
140.800 $/day
4364.800 $/month
2778.330 GB disk:
0.463 $/hr
11.113 $/day
344.512 $/month
Total Cost:
6.330 $/hr
151.913 $/day
4709.312 $/month
Internet :
31.403 $/TB

13.653 $/TB
$6.330/hr


================================================================





:16528host:85317verifiedVAST Verification Status48 GB4140.7 GB/s
W790 WS
PCIE 4.0,16x21.7 GB/s
CPU
96.0/96 cpu773/773 GB
Lexar SSD NM790 4TB
4347 MB/s3019.0 GB323 Mbps539 Mbps199 ports135.0 DLPerfMax CUDA: 12.4Max Duration
12 mon.
Reliability99.67%451.8 DLP/$/hr
$0.343/hr

================================================================
~~~~


m:16528host:85317verified48 GB4140.7 GB/s
W790 WS
Motherboard: W790 WSPCIE 4.0,16x21.7 GB/s
CPU
96.0/96 cpu773/773 GB
Lexar SSD NM790 4TB
4347 MB/s3019.0 GB323 Mbps539 Mbps199 ports135.0 DLPerfMax CUDA: 12.4Max Duration
12 mon.
Reliability99.67%193.2 DLP/$/hr
$0.699/hr
