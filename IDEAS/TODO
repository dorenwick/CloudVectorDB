


We need a way of making our data more anisitropic.

1:

first of all, we want a method that looks at all hard-negative candidates.
When we do this, we will want to compute square matrices of the embeddings.
after we do the filtering.

To do this, we will keep the distances of each embedding with each other, and store them during the embeddings computations.

2: I wish to test cagra's ability to index on the cloud, and test its retrieval ability. we should do this on a cheap pc.

3: Work alot on scoring systems, figure out what is best.


COMPUTE DISTANCE MATRICES!!!!!!!  Important.

We will keep the distance matrices of the embeddings.


================================================================

Once we have created our model, I wish to search using 20nn for each work, and create a dataset of
each work that is not being found on the encodings we have.

For each work object we do not find in our search through our whole index, we will take create a triplet from the 20nn
by searching for that specific work and creating a triplet from that work + two augmentations of it.

================================================================

We can go through our model, and for each work that isn't found on the 20 nn search, we will
actually just add them to a separate dataset, make triplets from them using knn-search,
and then fine-tune another encoder on those triplets, so we search via two encoders.






Type #12513877
Texas, US18x RTX 40901465.1  TFLOPSm:22133host:54858verified24 GB3435.2 GB/s
H12DSG
PCIE 4.0,8x12.8 GB/s
AMD EPYC 7B13 64-Core Processor
256.0/256 cpu2064/2064 GB
SAMSUNG MZQL23T8HCLS-00B7C
10314 MB/s6244.8 GB3997 Mbps3928 Mbps998 ports484.9 DLPerfMax CUDA: 12.4Max Duration
913 mon.
Reliability99.34%40.4 DLP/$/hr
$12.015/hr



m:16546host:53115verified24 GB787.5 GB/s
X10DRX
PCIE 3.0,8x5.7 GB/s
XeonÂ® E5-2690 v4
56.0/56 cpu258/258 GB
SAMSUNG MZ7KM960
1531 MB/s4561.5 GB98 Mbps874 Mbps998 ports144.4 DLPerfMax CUDA: 12.6Max Duration
21 days
Reliability99.04%54.1 DLP/$/hr
$2.671/hr


